name: Run Processor

on:
  workflow_dispatch:

  # To run the processor every time relevant files are pushed, uncomment the lines below:
  # push:
  #   paths:
  #     - 'tabular_data/config/**'
  #     - 'tabular_data/_global_config.py'
  #     - 'tabular_data/processor.py'
  #     - 'tabular_data/processor_helpers.py'
  #     - 'tabular_data/requirements.txt'
  #     - 'collections/**'
  #     - '*.xml'

  # The processor runs automatically at 03:30 UTC every Monday:
  schedule:
    - cron: '30 3 * * 1'

jobs:
  process:
    runs-on: ubuntu-latest

    env:
      LC_ALL: en_GB.UTF-8
      LANG: en_GB.UTF-8

    permissions:
      contents: write

    steps:
      - name: Checkout full repository
        uses: actions/checkout@v4
        with:
          ref: main
          fetch-depth: 0

      - name: Set up locale
        run: |
          sudo apt-get update
          sudo apt-get install -y locales
          sudo locale-gen en_GB.UTF-8
          sudo update-locale LANG=en_GB.UTF-8

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          cd tabular_data
          python -m venv .venv
          source .venv/bin/activate
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: Clear existing output
        run: |
          echo "Removing existing output directory..."
          rm -rf tabular_data/output
          mkdir -p tabular_data/output

      - name: Run processor
        run: |
          cd tabular_data
          source .venv/bin/activate
          python processor.py

      - name: Commit and force-push new output
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'

          echo "File list in new output (size in bytes):"
          find tabular_data/output -type f -printf "%s %p\n" | sort -nr | head -20

          # Remove any file >100MB
          while IFS= read -r bigfile; do
            echo "Skipped large file (>100MB): $bigfile"
            rm -f "$bigfile"
          done < <(find tabular_data/output -type f -size +100M)

          # Stage only the output directory
          git add -A tabular_data/output

          # Commit
          git commit -m "Update processor output"

          # Force push output changes
          git push origin main --force-with-lease
